
# Introduction

HTM is essentially a theory on how the human brain functions. Three brain features are critical in the development of  HTM. To begin with, the brain is a hierarchical organization by nature. Signals flow in both ways along the hierarchy. Additionally, there is signal flow within the region. Second, all of the information stored in the brain is temporal. All aspects of brain learning revolve around the concept of time. Finally, the human brain functions primarily as a memory system. Over time, we try to remember and predict patterns. In a way, all of the cells and their connections are storing the patterns that have been observed through time. Humans use the neocortex to learn sequences and predict the future, which is why Hawkins and George (2007) developed hierarchical temporal memory (HTM). It should be able to produce generalized representations for similar inputs in its idealized form. HTM should be able to perform time-dependent regression using its learned representations. Many applications utilizing spatiotemporal data would benefit greatly from such a system. Cui et al. (2016) used HTM to predict taxi passenger counts using time-series data. They used HTM for anomaly detection as well (Lavin and Ahmad 2015). The evolving nature of HTM's algorithmic definition and the lack of a formalized mathematical model have hampered its popularity in the machine learning community. Building a mathematical framework around HTM's original algorithmic definition, this work aims to bridge the gap between neuroscience-inspired algorithms and math-based algorithms.

# Summary of the Project

Hierarchical Temporal Memory (HTM), a machine learning approach that uses Spatial Pooler, Scalar Encoder and Temporal memory and having unit tests on the public functions. Hierarchical Temporal Memory (HTM) theory, which represents the structural and algorithmic aspects of neocortex, has recently developed a new paradigm in machine intelligence. There is still a lot of work to be done on the HTM algorithm's inference of patterns and structures recognized by the algorithm. The agility after testing the sequentially learned data while coinciding them with the input and output is the actual goal.

# Implementation

Through the GetPredictedInputValues() method, I've worked on or tested three public methods. The following is a breakdown of the methods' workings.

Some functions, on the other hand, didn't necessitate unit testing because they don't have any expected return values. The following are examples of some of those techniques. ActiveMap2.Clear() is present in the initial method ClearState, but it lacks the functionality needed to be tested in a unit test. Learn(TIN input, Cell[] output) is the second function's Learn(TIN input, Cell[] output) where the learning process begins after this technique, from whence we acquired the sequences that determine the HTM region parameters.
Scalar encoder, spatial pooler, temporal memory, input, and other encoders all function simultaneously in these locations, and the hierarchical temporal memories play a crucial part in obtaining the required output from the system.

~~~csharp
public void ClearState()
        {
            m_ActiveMap2.Clear();
        }
public void Learn(TIN input, Cell[] output)
        {
        }
~~~
Non-returning htmClassifier methods

The very first standard method on which I worked is CheckHowManyOfGetPredictedInputValues() where I have checked that the data sent through ‘howMany’ parameters are equal to the ‘res’ variable value which is counted by Count==howMany. So, the goal we set for our GetPredictedInputValues() method is being met by this unit test.

~~~csharp
public void CheckHowManyOfGetPredictedInputValues(int howMany)
        {
            sequences = new Dictionary<string, List<double>>();
            sequences.Add("S1", new List<double>(new double[] { 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, }));

            LearnHtmClassifier();

            var lyrOut = layer.Compute(1, false) as ComputeCycle;

            var res = htmClassifier.GetPredictedInputValues(lyrOut.PredictiveCells.ToArray(), Convert.ToInt16(howMany));

            Assert.IsTrue(res.Count==howMany);
        }
~~~
This code snippet checks that the 'howMany' parameter value is equal to the Count==howMany variable value.


The next function, NoExceptionIfCellsCountIsZero(), demonstrates that if we send cells count '0', it checks for the exception. CheckHowManyOfGetPredictedInputValues(), on the other hand, does not throw an exception in this instance. So, it is maintained that the method htm.Classifier.GetPredictedInputValues() returns the precise number of predicted input values that we sought to forecast.

~~~csharp
public void NoExceptionIfCellsCountIsZero()
        {
            Cell[] cells = new Cell[0];
            var res = htmClassifier.GetPredictedInputValues(cells, 3);
            Assert.AreEqual(res.Count,0);
        }
~~~
NoExceptionIfCellsCountIsZero() where it is showing that if we send cells count ‘0’, it checks for the exception.

The third and the last unit test plays very important role for the HTMClassifier. I examine the input sequence and output sequence is same after learning our data through the method LearHtmClassifier(). For example, here in the code below is demonstrating that the input sequence-3 is equal to output sequence-3 after checking through the predicted method, GetPredictedInputValues(). Assuming the previous step correctly anticipated the current value, we have a match. It is impossible to foresee the sequence's first element (a single element). If we achieve 30 repetitions with 100percentage accuracy, the trial is over. As a result, the first element will always begin at the beginning of the learning process.

~~~csharp
public void CheckNextValueIsNotEmpty()
        {
            sequences = new Dictionary<string, List<double>>();
            sequences.Add("S1", new List<double>(new double[] { 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, }));

            LearnHtmClassifier();

            //var tm = layer1.HtmModules.FirstOrDefault(m => m.Value is TemporalMemory);
            //((TemporalMemory)tm.Value).Reset(mem);

            var lyrOut = layer.Compute(1, false) as ComputeCycle;

            var res = htmClassifier.GetPredictedInputValues(lyrOut.PredictiveCells.ToArray(), 3);

            var tokens = res.First().PredictedInput.Split('_');
            var tokens2 = res.First().PredictedInput.Split('-');
            var predictValue = Convert.ToInt32(tokens2[tokens.Length - 1]);
            Assert.IsTrue(predictValue > 0);
        }
~~~
It tests the input sequence and output sequence are same after learning our data through the method LearHtmClassifier().
